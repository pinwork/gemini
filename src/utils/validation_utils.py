#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import phonenumbers
import logging
from urllib.parse import urlparse, urlunparse

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏
URL_FIELDS = ["blog_url", "recruits_affiliates_url", "contact_page_url", "api_documentation_url"]

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥–µ—Ä–∞ –¥–ª—è validation_utils (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ segmentation_validation)
logger = logging.getLogger("segmentation_validation")

# –ü–æ–ø—É–ª—è—Ä–Ω—ñ –Ω–∞–∑–≤–∏ –º–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó
LANGUAGE_NAME_TO_CODE = {
    # –ê–Ω–≥–ª—ñ–π—Å—å–∫—ñ –Ω–∞–∑–≤–∏
    "english": "en", "german": "de", "japanese": "ja", "french": "fr", "spanish": "es",
    "indonesian": "id", "russian": "ru", "portuguese": "pt", "dutch": "nl", "italian": "it",
    "chinese": "zh", "korean": "ko", "vietnamese": "vi", "polish": "pl", "turkish": "tr",
    "ukrainian": "uk", "thai": "th", "arabic": "ar", "swedish": "sv", "czech": "cs",
    "hungarian": "hu", "finnish": "fi", "danish": "da", "norwegian": "no", "greek": "el",
    "hebrew": "he", "hindi": "hi",
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –Ω–∞–∑–≤–∏
    "deutsch": "de", "fran√ßais": "fr", "francais": "fr", "espa√±ol": "es", "espanol": "es",
    "portugu√™s": "pt", "portugues": "pt", "italiano": "it", "—Ä—É—Å—Å–∫–∏–π": "ru", "russkiy": "ru",
    "nederlands": "nl", "svenska": "sv", "norsk": "no", "suomi": "fi", "magyar": "hu",
    "ƒçe≈°tina": "cs", "cestina": "cs", "polski": "pl", "t√ºrk√ße": "tr", "turkce": "tr",
    
    # –°–∫–æ—Ä–æ—á–µ–Ω—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏  
    "eng": "en", "ger": "de", "jap": "ja", "jpn": "ja", "fre": "fr", "spa": "es",
    "por": "pt", "ita": "it", "rus": "ru", "chi": "zh", "kor": "ko", "vie": "vi",
    "pol": "pl", "tur": "tr", "ukr": "uk", "ara": "ar", "swe": "sv", "cze": "cs",
    "hun": "hu", "fin": "fi", "dan": "da", "nor": "no"
}


def clean_phone_for_validation(phone: str) -> str:
    """
    –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –æ—á–∏—Å—Ç–∫–∞ –Ω–æ–º–µ—Ä–∞ –¥–ª—è –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è —à–∞–Ω—Å—ñ–≤ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    
    Args:
        phone: –ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        
    Returns:
        –û—á–∏—â–µ–Ω–∏–π –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É
    """
    if not phone:
        return ""
    
    # –í–∏–¥–∞–ª—è—î–º–æ –ø—Ä–æ–±—ñ–ª–∏, –¥—É–∂–∫–∏, —Ç–∏—Ä–µ
    cleaned = re.sub(r'[\s\(\)\-\.]', '', phone)
    
    # –Ø–∫—â–æ –Ω–µ–º–∞—î +, –∞–ª–µ —î —Ü–∏—Ñ—Ä–∏, –¥–æ–¥–∞—î–º–æ +
    if cleaned and not cleaned.startswith('+') and cleaned[0].isdigit():
        cleaned = '+' + cleaned
    
    return cleaned


def format_summary(summary_text: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç—É—î summary text - —Ä–æ–±–∏—Ç—å –ø–µ—Ä—à—É –ª—ñ—Ç–µ—Ä—É –≤–µ–ª–∏–∫–æ—é, –¥–æ–¥–∞—î –∫—Ä–∞–ø–∫—É –≤ –∫—ñ–Ω—Ü—ñ
    
    Args:
        summary_text: –¢–µ–∫—Å—Ç summary –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è
        
    Returns:
        –í—ñ–¥—Ñ–æ—Ä–º–∞—Ç–æ–≤–∞–Ω–∏–π summary text
    """
    if not summary_text:
        return summary_text
    
    text = summary_text.strip()
    if not text:
        return text
    
    # –†–æ–±–∏–º–æ –ø–µ—Ä—à—É –ª—ñ—Ç–µ—Ä—É –≤–µ–ª–∏–∫–æ—é
    text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()
    
    # –†–æ–±–∏–º–æ –≤–µ–ª–∏–∫–∏–º–∏ –ª—ñ—Ç–µ—Ä–∏ –ø—ñ—Å–ª—è –∫—Ä–∞–ø–æ–∫
    text = re.sub(r'\. ([a-z])', lambda m: '. ' + m.group(1).upper(), text)
    
    # –î–æ–¥–∞—î–º–æ –∫—Ä–∞–ø–∫—É –≤ –∫—ñ–Ω—Ü—ñ —è–∫—â–æ –Ω–µ–º–∞—î
    if not text.endswith('.'):
        text += '.'
    
    # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ –ø–æ–¥–≤—ñ–π–Ω—ñ –∫—Ä–∞–ø–∫–∏
    text = re.sub(r'\.\.+', '.', text)
    
    return text


def clean_it_prefix(text_value: str) -> str:
    """
    –ü—Ä–∏–±–∏—Ä–∞—î –ø—Ä–µ—Ñ—ñ–∫—Å "it " –∑ –ø–æ—á–∞—Ç–∫—É —Ç–µ–∫—Å—Ç—É
    
    Args:
        text_value: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–æ–±–∫–∏
        
    Returns:
        –¢–µ–∫—Å—Ç –±–µ–∑ "it " –ø—Ä–µ—Ñ—ñ–∫—Å–∞
    """
    if not text_value:
        return text_value
    
    if text_value.lower().startswith("it "):
        return text_value[3:].strip()
    
    return text_value


def clean_app_platforms(app_platforms_value) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î app_platforms –∑ array –≤ –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏–π string —á–µ—Ä–µ–∑ –∫–æ–º—É
    
    Args:
        app_platforms_value: Array –∞–±–æ string –ø–ª–∞—Ç—Ñ–æ—Ä–º –≤—ñ–¥ Gemini API
        
    Returns:
        –í—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏–π string —á–µ—Ä–µ–∑ –∫–æ–º—É –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    """
    if not app_platforms_value:
        return ""
    
    if isinstance(app_platforms_value, list):
        # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è —Ç–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏
        valid_platforms = [platform.strip().lower() for platform in app_platforms_value if platform and platform.strip()]
        unique_platforms = list(dict.fromkeys(valid_platforms))  # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –ø–æ—Ä—è–¥–æ–∫
        
        # –°–æ—Ä—Ç—É—î–º–æ –ø–æ –∞–ª—Ñ–∞–≤—ñ—Ç—É
        sorted_platforms = sorted(unique_platforms)
        
        return ", ".join(sorted_platforms)
    
    elif isinstance(app_platforms_value, str):
        # –Ø–∫—â–æ –ø—Ä–∏–π—à–æ–≤ string - –æ–±—Ä–æ–±–ª—è—î–º–æ —è–∫ —Ä–∞–Ω—ñ—à–µ
        platforms = [p.strip().lower() for p in app_platforms_value.split(",") if p.strip()]
        unique_platforms = list(dict.fromkeys(platforms))
        sorted_platforms = sorted(unique_platforms)
        return ", ".join(sorted_platforms)
    
    return ""


def has_access_issues(field_value: str, field_name: str = "") -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ –º—ñ—Å—Ç–∏—Ç—å –ø–æ–ª–µ –ø—Ä–æ–±–ª–µ–º–∏ –¥–æ—Å—Ç—É–ø—É –∞–±–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    
    Args:
        field_value: –ó–Ω–∞—á–µ–Ω–Ω—è –ø–æ–ª—è –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        field_name: –ù–∞–∑–≤–∞ –ø–æ–ª—è (–¥–ª—è —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏)
        
    Returns:
        True —è–∫—â–æ –ø–æ–ª–µ –º–∞—î –ø—Ä–æ–±–ª–µ–º–∏ –¥–æ—Å—Ç—É–ø—É
    """
    if not field_value:
        return False
        
    field_lower = field_value.strip().lower()
    
    # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è enum –ø–æ–ª—ñ–≤
    enum_fields_with_unspecified = ["target_age_group", "target_gender", "domain_formation_pattern"]
    if field_name in enum_fields_with_unspecified and field_lower == "unspecified":
        return False
    
    # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è segments_language
    if field_name == "segments_language":
        special_values = {"mixed", "unknown"}
        if field_lower in special_values or (len(field_value.strip()) == 2 and field_value.strip().isalpha()):
            return False
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
    access_issues = [
        "unclear" in field_lower,
        field_lower == "unspecified",
        "unavailable" in field_lower,
        "not available" in field_lower,
        "not accessible" in field_lower,
        "inaccessible" in field_lower,
        "not determinable" in field_lower,
        field_lower == "cannot be determined",
        field_lower == "not detected",
        "unable" in field_lower,
        "cannot access" in field_lower,
        "can't access" in field_lower,
        "access denied" in field_lower,
        "access failed" in field_lower,
        "access error" in field_lower,
        "no access" in field_lower,
        field_lower == "error",
        field_lower == "failed",
        field_lower == "blocked",
        field_lower == "forbidden",
        field_lower == "restricted",
        field_lower == "timeout",
        field_lower == "unreachable",
        "site blocked" in field_lower,
        "website error" in field_lower,
        "site error" in field_lower,
        "website failed" in field_lower,
        "site failed" in field_lower,
        "website timeout" in field_lower,
        "site timeout" in field_lower,
        "website unreachable" in field_lower,
        "site unreachable" in field_lower,
        "access_unable" in field_lower,
        field_lower == "this platform",
        field_lower == "string",
        field_lower == "n/a",
        field_lower == "none",
        field_lower == "null",
    ]
    
    # "unknown" —î –ø—Ä–æ–±–ª–µ–º–æ—é –¥–æ—Å—Ç—É–ø—É –¥–ª—è –≤—Å—ñ—Ö –ø–æ–ª—ñ–≤, –∫—Ä—ñ–º segments_language
    if field_lower == "unknown" and field_name != "segments_language":
        access_issues.append(True)
    
    return any(access_issues)


def validate_country_code(country_code: str) -> bool:
    """
    –í–∞–ª—ñ–¥—É—î 2-–ª—ñ—Ç–µ—Ä–Ω–∏–π ISO –∫–æ–¥ –∫—Ä–∞—ó–Ω–∏
    
    Args:
        country_code: –ö–æ–¥ –∫—Ä–∞—ó–Ω–∏ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        
    Returns:
        True —è–∫—â–æ –∫–æ–¥ –≤–∞–ª—ñ–¥–Ω–∏–π
    """
    if not country_code or len(country_code.strip()) != 2:
        return False
    return country_code.strip().isalpha()


def validate_and_clean_language_code(language_value: str) -> str:
    """
    –†–æ–∑—É–º–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è —Ç–∞ –æ—á–∏—Å—Ç–∫–∞ –∫–æ–¥—É –º–æ–≤–∏
    
    Args:
        language_value: –ó–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏ –≤—ñ–¥ Gemini API
        
    Returns:
        –í–∞–ª—ñ–¥–Ω–∏–π ISO 639-1 –∫–æ–¥ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    """
    if not language_value:
        return ""
    
    # –û—á–∏—â–∞—î–º–æ —Ç–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ
    cleaned = language_value.strip().lower()
    if not cleaned:
        return ""
    
    # 1. ‚úÖ –Ø–ö–©–û –í–ñ–ï 2 –ë–£–ö–í–ò - –ü–†–û–ü–£–°–ö–ê–Ñ–ú–û –ë–ï–ó –í–ê–õ–Ü–î–ê–¶–Ü–á
    if len(cleaned) == 2 and cleaned.isalpha():
        return cleaned  # xy, zz, qq - –≤—Å–µ –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ!
    
    # 2. –û–±—Ä–æ–±–∫–∞ locale –∫–æ–¥—ñ–≤ –∑ –¥–µ—Ñ—ñ—Å–æ–º (zh-tw, en-us, fr-ca)
    if "-" in cleaned and len(cleaned) <= 6:
        language_part = cleaned.split("-")[0]
        if len(language_part) == 2 and language_part.isalpha():
            return language_part  # –ë—É–¥—å-—è–∫–∏–π 2-–±—É–∫–≤–µ–Ω–Ω–∏–π –∫–æ–¥
    
    # 3. –û–±—Ä–æ–±–∫–∞ underscore –∫–æ–¥—ñ–≤ (en_US, zh_CN)
    if "_" in cleaned and len(cleaned) <= 6:
        language_part = cleaned.split("_")[0]
        if len(language_part) == 2 and language_part.isalpha():
            return language_part  # –ë—É–¥—å-—è–∫–∏–π 2-–±—É–∫–≤–µ–Ω–Ω–∏–π –∫–æ–¥
    
    # 4. –ü–æ—à—É–∫ —É —Å–ª–æ–≤–Ω–∏–∫—É –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö –Ω–∞–∑–≤
    if cleaned in LANGUAGE_NAME_TO_CODE:
        return LANGUAGE_NAME_TO_CODE[cleaned]
    
    # 5. –ß–∞—Å—Ç–∫–æ–≤–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö –º–æ–≤ (english -> en)
    for lang_name, lang_code in LANGUAGE_NAME_TO_CODE.items():
        if lang_name in cleaned or cleaned in lang_name:
            # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ false positives
            if len(lang_name) >= 4 and len(cleaned) >= 4:
                return lang_code
    
    # 6. –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ –ø—ñ–¥—ñ–π—à–ª–æ - –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    return ""


def validate_email(email: str) -> bool:
    """
    –ë–∞–∑–æ–≤–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è email –∞–¥—Ä–µ—Å–∏
    
    Args:
        email: Email –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        
    Returns:
        True —è–∫—â–æ email –≤–∞–ª—ñ–¥–Ω–∏–π
    """
    if not email or "@" not in email:
        return False
    email = email.strip().lower()
    if email.count("@") != 1:
        return False
    local, domain = email.split("@")
    if not local or not domain or "." not in domain:
        return False
    return True


def validate_phone_e164(phone: str) -> bool:
    """
    –í–∞–ª—ñ–¥—É—î –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É –≤ E164 —Ñ–æ—Ä–º–∞—Ç—ñ
    
    Args:
        phone: –ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω—É –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        
    Returns:
        True —è–∫—â–æ –Ω–æ–º–µ—Ä –≤–∞–ª—ñ–¥–Ω–∏–π
    """
    if not phone or not phone.startswith("+"):
        return False
    digits = phone[1:]
    if not digits.isdigit() or len(digits) < 7 or len(digits) > 15:
        return False
    return True


def validate_segments_language(segments_language: str) -> bool:
    """
    –í–∞–ª—ñ–¥—É—î –∫–æ–¥ –º–æ–≤–∏ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥–æ–º–µ–Ω—É.
    –ü–æ–≤–µ—Ä—Ç–∞—î True —è–∫—â–æ —Ü–µ –≤–∞–ª—ñ–¥–Ω–∏–π ISO 639-1 –∫–æ–¥ –∞–±–æ –¥–æ–∑–≤–æ–ª–µ–Ω–µ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è.
    
    Args:
        segments_language: –ö–æ–¥ –º–æ–≤–∏ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        
    Returns:
        True —è–∫—â–æ –∫–æ–¥ –≤–∞–ª—ñ–¥–Ω–∏–π
    """
    if not segments_language:
        return False
    
    language_code = segments_language.strip().lower()
    
    # –î–æ–∑–≤–æ–ª–µ–Ω—ñ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    special_values = {"mixed", "unknown"}
    if language_code in special_values:
        return True
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–≤–æ–±—É–∫–≤–µ–Ω–Ω–æ–≥–æ ISO 639-1 –∫–æ–¥—É
    if len(language_code) == 2 and language_code.isalpha():
        return True
    
    logger.warning(f"Invalid segments_language: '{segments_language}' - must be 2-letter ISO code or 'mixed'/'unknown'")
    return False


def normalize_url(url_value: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑—É—î URL –¥–æ –∫–∞–Ω–æ–Ω—ñ—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç—É
    
    Args:
        url_value: URL –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
        
    Returns:
        –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π URL –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫ —è–∫—â–æ –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π
    """
    if not url_value:
        return url_value
    
    url_stripped = url_value.strip()
    
    if not (url_stripped.lower().startswith('http://') or url_stripped.lower().startswith('https://')):
        return ""
    
    try:
        parsed = urlparse(url_stripped)
        
        normalized = urlunparse((
            parsed.scheme,
            parsed.netloc,
            parsed.path,
            parsed.params,
            parsed.query,
            ''
        ))
        
        if not normalized.endswith('/'):
            normalized += '/'
            
        return normalized
        
    except Exception:
        return ""


def validate_url_field(url_value: str, target_uri: str) -> str:
    """
    –í–∞–ª—ñ–¥—É—î URL –ø–æ–ª–µ —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—é—î –∑ target_uri
    
    Args:
        url_value: URL –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
        target_uri: –ë–∞–∑–æ–≤–∏–π URI –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
        
    Returns:
        –í–∞–ª—ñ–¥–Ω–∏–π URL –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    """
    if not url_value:
        return url_value
    
    normalized_url = normalize_url(url_value)
    
    if not normalized_url:
        return ""
    
    normalized_target = normalize_url(target_uri)
    
    # –Ø–∫—â–æ URL —ñ–¥–µ–Ω—Ç–∏—á–Ω–∏–π target_uri, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    if normalized_url.lower() == normalized_target.lower():
        return ""
    
    return normalized_url


def _segments_norm(s: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏: –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –ø—Ä–æ–±—ñ–ª–∏ —Ç–∞ —Ä–µ–≥—ñ—Å—Ç—Ä
    
    Args:
        s: –†—è–¥–æ–∫ –¥–ª—è –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
        
    Returns:
        –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–∏–π —Ä—è–¥–æ–∫
    """
    return s.replace(' ', '').lower() if s else ''


def validate_segments_full(segment_combined: str, segments_full: str, domain_full: str = "") -> bool:
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –∫–æ—Ä–µ–∫—Ç–Ω–æ –®–Ü —Å–µ–≥–º–µ–Ω—Ç—É–≤–∞–≤ –¥–æ–º–µ–Ω –∑ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–º –ª–æ–≥—É–≤–∞–Ω–Ω—è–º
    
    Args:
        segment_combined: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è (–∑ –ø—Ä–æ–±—ñ–ª–∞–º–∏)
        segments_full: AI –ø–æ–≤–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è (–∑ –ø—Ä–æ–±—ñ–ª–∞–º–∏)
        domain_full: –î–æ–º–µ–Ω –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        True —è–∫—â–æ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –ø—Ä–æ–π—à–ª–∞
    """
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø–æ—Ä–æ–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    if not segment_combined:
        return False
    
    if not segments_full:
        if domain_full:
            # üéØ –ö–û–†–û–¢–ö–ï –ª–æ–≥—É–≤–∞–Ω–Ω—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π —Ñ–∞–π–ª
            logger.warning(f"Domain {domain_full}: segments_full validation failed | AI returned: <empty>")
        return False

    # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ: –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –ø—Ä–æ–±—ñ–ª–∏ —Ç–∞ —Ä–µ–≥—ñ—Å—Ç—Ä
    original_normalized = _segments_norm(segment_combined)
    ai_normalized = _segments_norm(segments_full)

    # –°–∫–ª–µ–π–∫–∞ –º–∞—î –∑–±—ñ–≥–∞—Ç–∏—Å—è
    validation_passed = original_normalized == ai_normalized
    
    if not validation_passed and domain_full:
        # üéØ –ú–Ü–ù–Ü–ú–ê–õ–¨–ù–ï –ª–æ–≥—É–≤–∞–Ω–Ω—è - —Ç—ñ–ª—å–∫–∏ –¥–æ–º–µ–Ω —ñ —â–æ –ø–æ–≤–µ—Ä–Ω—É–≤ AI
        logger.warning(f"Domain {domain_full}: segments_full validation failed | AI returned: '{segments_full}'")
    
    return validation_passed


def clean_segments_language(language_value: str) -> str:
    """
    –û—á–∏—â–∞—î segments_language - –≤–∏–±–∏—Ä–∞—î –ü–ï–†–®–ï –≤–∞–ª—ñ–¥–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è
    
    Args:
        language_value: –ó–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤–∏ (–º–æ–∂–µ –±—É—Ç–∏ "en en" –∞–±–æ "en fr")
        
    Returns:
        –û–¥–Ω–µ –≤–∞–ª—ñ–¥–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    """
    if not language_value:
        return ""
    
    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
    parts = language_value.strip().split()
    if not parts:
        return ""
    
    # –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∏ –¥–ª—è –≤–∏–±–æ—Ä—É
    special_values = {"mixed", "unknown"}
    
    # –°–ø–æ—á–∞—Ç–∫—É —à—É–∫–∞—î–º–æ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    for part in parts:
        part_lower = part.lower()
        if part_lower in special_values:
            return part_lower
    
    # –ü–æ—Ç—ñ–º —à—É–∫–∞—î–º–æ –≤–∞–ª—ñ–¥–Ω—ñ ISO –∫–æ–¥–∏ (2 –ª—ñ—Ç–µ—Ä–∏)
    for part in parts:
        part_clean = part.strip().lower()
        if len(part_clean) == 2 and part_clean.isalpha():
            return part_clean
    
    # –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç
    return parts[0].lower()


def clean_segmentation_field(field_value: str, field_name: str) -> str:
    """
    –û—á–∏—â–∞—î –ø–æ–ª–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó –≤—ñ–¥ –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
    
    Args:
        field_value: –ó–Ω–∞—á–µ–Ω–Ω—è –ø–æ–ª—è
        field_name: –ù–∞–∑–≤–∞ –ø–æ–ª—è
        
    Returns:
        –û—á–∏—â–µ–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∞–±–æ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä—è–¥–æ–∫
    """
    if not field_value or has_access_issues(field_value, field_name):
        return ""
    return field_value.strip()


def clean_all_segmentation_fields(segment_combined: str, gemini_result: dict) -> dict:
    """
    –û—á–∏—â–∞—î –í–°–Ü –ø–æ–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó –≤—ñ–¥ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ —â–æ –Ω–µ –≤—Ö–æ–¥—è—Ç—å –≤ domain_core
    
    Args:
        segment_combined: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è domain_core
        gemini_result: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—ñ–¥ Gemini
        
    Returns:
        –û—á–∏—â–µ–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –∑ –≤–∞–ª—ñ–¥–Ω–∏–º–∏ —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
    """
    if not segment_combined:
        return gemini_result
    
    # –ì–µ–Ω–µ—Ä—É—î–º–æ domain_core segments (–¥–∂–µ—Ä–µ–ª–æ –ø—Ä–∞–≤–¥–∏)
    valid_segments = set(segment_combined.split())
    
    # –û—á–∏—â–∞—î–º–æ –í–°–Ü —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω—ñ –ø–æ–ª—è –æ–¥–Ω–∞–∫–æ–≤–æ
    segmentation_fields = [
        "segments_full", "segments_primary", "segments_descriptive", 
        "segments_prefix", "segments_suffix", "segments_thematic", "segments_common"
    ]
    
    for field_name in segmentation_fields:
        if field_name in gemini_result:
            field_value = gemini_result[field_name]
            if field_value:
                # –ó–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∏ —â–æ –≤—Ö–æ–¥—è—Ç—å –≤ domain_core
                cleaned_segments = [seg for seg in field_value.split() 
                                  if seg in valid_segments]
                gemini_result[field_name] = " ".join(cleaned_segments)
    
    return gemini_result


def clean_geo_fields(gemini_result: dict) -> dict:
    """
    –û—á–∏—â–∞—î –≥–µ–æ–≥—Ä–∞—Ñ—ñ—á–Ω—ñ –ø–æ–ª—è –∑ –≤–∞–ª—ñ–¥–∞—Ü—ñ—î—é country code
    –Ø–∫—â–æ geo_country –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π - –æ—á–∏—â–∞—î –≤—Å—ñ geo –ø–æ–ª—è
    
    Args:
        gemini_result: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—ñ–¥ Gemini
        
    Returns:
        –û—á–∏—â–µ–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –∑ –≤–∞–ª—ñ–¥–Ω–∏–º–∏ geo –ø–æ–ª—è–º–∏
    """
    geo_country = gemini_result.get("geo_country", "").strip()
    
    # –í–∞–ª—ñ–¥—É—î–º–æ geo_country
    if geo_country and validate_country_code(geo_country):
        # Country –≤–∞–ª—ñ–¥–Ω–∏–π - –∑–∞–ª–∏—à–∞—î–º–æ –≤—Å—ñ geo –ø–æ–ª—è
        gemini_result["geo_country"] = geo_country.upper()  # ISO –∫–æ–¥–∏ –∑–∞–∑–≤–∏—á–∞–π uppercase
        # geo_region —ñ geo_city –∑–∞–ª–∏—à–∞—é—Ç—å—Å—è —è–∫ —î
    else:
        # Country –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π - –æ—á–∏—â–∞—î–º–æ –í–°–Ü geo –ø–æ–ª—è
        gemini_result["geo_country"] = ""
        gemini_result["geo_region"] = ""
        gemini_result["geo_city"] = ""
    
    return gemini_result


def handle_segments_full_validation(gemini_result: dict, domain_full: str = "") -> dict:
    """
    –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è –ø–æ–ª—è segments_full
    –Ø–∫—â–æ –ø—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤–æ–Ω–æ —Å—Ç–∞—î –ø–æ—Ä–æ–∂–Ω—ñ–º - –∑–∞–ø–∏—Å—É—î "validation_failed"
    
    Args:
        gemini_result: –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏
        domain_full: –î–æ–º–µ–Ω –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –ú–æ–¥–∏—Ñ—ñ–∫–æ–≤–∞–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –∑ –æ–±—Ä–æ–±–ª–µ–Ω–∏–º segments_full
    """
    segments_full = gemini_result.get("segments_full", "").strip()
    
    # –Ø–∫—â–æ segments_full –ø–æ—Ä–æ–∂–Ω—î –ø—ñ—Å–ª—è –æ—á–∏—Å—Ç–∫–∏ - –∑–∞–ø–∏—Å—É—î–º–æ validation_failed
    if not segments_full:
        gemini_result["segments_full"] = "validation_failed"
        if domain_full:
            logger.info(f"Domain {domain_full}: segments_full set to 'validation_failed' due to empty value after cleaning")
        else:
            logger.info(f"segments_full set to 'validation_failed' due to empty value after cleaning")
    
    return gemini_result


def clean_gemini_results(gemini_result: dict, segment_combined: str = "", domain_full: str = "") -> dict:
    """
    –û—á–∏—â–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—ñ–¥ Gemini API - –≤–∞–ª—ñ–¥—É—î –Ω–æ–º–µ—Ä–∏ —Ç–µ–ª–µ—Ñ–æ–Ω—ñ–≤ —Ç–∞ –ø—Ä–∏–±–∏—Ä–∞—î –ø—Ä–æ–±–ª–µ–º–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
    
    Args:
        gemini_result: –°–ª–æ–≤–Ω–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –≤—ñ–¥ Gemini
        segment_combined: –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        domain_full: –î–æ–º–µ–Ω –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥—É–≤–∞–Ω–Ω—è (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –û—á–∏—â–µ–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    """
    cleaned_result = {}
    
    # –°–ø–∏—Å–æ–∫ –Ω–æ–≤–∏—Ö –ø–æ–ª—ñ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó
    segmentation_fields = [
        "segments_full", "segments_primary", "segments_descriptive", 
        "segments_prefix", "segments_suffix", "segments_thematic", "segments_common"
    ]
    
    for key, value in gemini_result.items():
        if key == "phone_list" and isinstance(value, list):
            # –í–∞–ª—ñ–¥–∞—Ü—ñ—è –Ω–æ–º–µ—Ä—ñ–≤ —Ç–µ–ª–µ—Ñ–æ–Ω—ñ–≤
            validated_phones = []
            for phone_data in value:
                if isinstance(phone_data, dict) and phone_data.get("phone_number"):
                    phone = phone_data.get("phone_number", "").strip()
                    
                    # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –æ—á–∏—Å—Ç–∫–∞
                    cleaned_phone = clean_phone_for_validation(phone)
                    
                    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è —á–µ—Ä–µ–∑ phonenumbers
                    try:
                        if cleaned_phone:
                            parsed = phonenumbers.parse(cleaned_phone, None)
                            if phonenumbers.is_valid_number(parsed):
                                formatted_number = phonenumbers.format_number(parsed, phonenumbers.PhoneNumberFormat.E164)
                                region_code = phonenumbers.region_code_for_number(parsed) or "UNKNOWN"
                                
                                validated_phones.append({
                                    "phone_number": formatted_number,
                                    "region_code": region_code.upper(),
                                    "whatsapp": phone_data.get("whatsapp", False),
                                    "contact_type": phone_data.get("contact_type", "")
                                })
                    except phonenumbers.NumberParseException:
                        # –Ø–∫—â–æ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –Ω–µ –ø—Ä–æ–π—à–ª–∞ - –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –Ω–æ–º–µ—Ä
                        pass
            
            cleaned_result[key] = validated_phones
            
        elif key == "app_platforms":
            # üÜï –ù–û–í–ê –û–ë–†–û–ë–ö–ê: array ‚Üí sorted string
            cleaned_result[key] = clean_app_platforms(value)
            
        elif isinstance(value, str):
            if key == "segments_language":
                # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ—á–∏—Å—Ç–∫–∞ –¥–ª—è segments_language –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
                cleaned_lang = clean_segments_language(value)
                cleaned_result[key] = cleaned_lang
            elif key == "primary_language":
                # üÜï –†–û–ó–£–ú–ù–ê –í–ê–õ–Ü–î–ê–¶–Ü–Ø –¥–ª—è primary_language
                cleaned_result[key] = validate_and_clean_language_code(value)
            elif key in segmentation_fields:
                # –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–ª—è –ø–æ–ª—ñ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—ó
                cleaned_result[key] = clean_segmentation_field(value, key)
            elif has_access_issues(value, key):
                cleaned_result[key] = ""
            elif key == "summary":
                cleaned_result[key] = format_summary(clean_it_prefix(value))
            elif key in ["similarity_search_phrases", "vector_search_phrase"]:
                cleaned_result[key] = clean_it_prefix(value)
            else:
                cleaned_result[key] = value
        elif isinstance(value, int):
            cleaned_result[key] = value
        else:
            cleaned_result[key] = value
    
    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ –æ—á–∏—Å—Ç–∫—É —Å–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ–π–Ω–∏—Ö –ø–æ–ª—ñ–≤
    if segment_combined:
        cleaned_result = clean_all_segmentation_fields(segment_combined, cleaned_result)
    
    # üåç –ù–û–í–ê –û–ë–†–û–ë–ö–ê: –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –≥–µ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∏—Ö –ø–æ–ª—ñ–≤
    cleaned_result = clean_geo_fields(cleaned_result)
    
    # üîß –ù–û–í–ê –§–£–ù–ö–¶–Ü–û–ù–ê–õ–¨–ù–Ü–°–¢–¨: —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ segments_full
    cleaned_result = handle_segments_full_validation(cleaned_result, domain_full)
    
    return cleaned_result


if __name__ == "__main__":
    # –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è validation_utils –º–æ–¥—É–ª—è
    print("=== Validation Utils Test Suite ===\n")
    
    # –¢–µ—Å—Ç 1: Email –≤–∞–ª—ñ–¥–∞—Ü—ñ—è
    print("1. Email Validation Tests:")
    test_emails = [
        "valid@example.com",
        "user.name@domain.co.uk", 
        "invalid-email",
        "@invalid.com",
        "user@",
        "test@domain",
        ""
    ]
    for email in test_emails:
        result = validate_email(email)
        print(f"   '{email}' ‚Üí {result}")
    
    # –¢–µ—Å—Ç 2: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–±–ª–µ–º –¥–æ—Å—Ç—É–ø—É
    print("\n2. Access Issues Detection:")
    test_texts = [
        "Product management platform",  # Valid
        "unclear",                      # Access issue
        "not detected",                # Access issue
        "Payment service provider",     # Valid
        "unavailable",                 # Access issue
        "en",                          # Valid for language
        "unknown"                      # Context dependent
    ]
    for text in test_texts:
        result = has_access_issues(text)
        print(f"   '{text}' ‚Üí Has issues: {result}")
    
    # –¢–µ—Å—Ç 3: –û—á–∏—Å—Ç–∫–∞ segments_language
    print("\n3. Segments Language Cleaning:")
    test_languages = [
        "en en",
        "de de de",
        "mixed",
        "en fr", 
        "unknown",
        "mixed unknown",
        "garbage en",
        "123 mixed de"
    ]
    for lang in test_languages:
        result = clean_segments_language(lang)
        print(f"   '{lang}' ‚Üí '{result}'")
    
    # –¢–µ—Å—Ç 4: –û—á–∏—Å—Ç–∫–∞ app_platforms
    print("\n4. App Platforms Cleaning:")
    test_platforms = [
        ["windows", "android", "chrome", "android"],  # Array –∑ –¥—É–±–ª—ñ–∫–∞—Ç–∞–º–∏
        ["ios", "safari"],                             # Array –±–µ–∑ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤
        [],                                            # –ü–æ—Ä–æ–∂–Ω—ñ–π array
        "windows, chrome, android",                    # String (—Å—Ç–∞—Ä–∏–π —Ñ–æ—Ä–º–∞—Ç)
        "",                                            # –ü–æ—Ä–æ–∂–Ω—ñ–π string
        None                                           # None
    ]
    for platforms in test_platforms:
        result = clean_app_platforms(platforms)
        print(f"   {platforms} ‚Üí '{result}'")
    
    # –¢–µ—Å—Ç 5: –ì–µ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è
    print("\n5. Geo Fields Validation:")
    test_geo_cases = [
        {"geo_country": "US", "geo_region": "CA", "geo_city": "San Francisco"},      # –í–∞–ª—ñ–¥–Ω–∏–π
        {"geo_country": "GB", "geo_region": "London", "geo_city": "London"},        # –í–∞–ª—ñ–¥–Ω–∏–π
        {"geo_country": "USA", "geo_region": "CA", "geo_city": "San Francisco"},    # –ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π country
        {"geo_country": "123", "geo_region": "CA", "geo_city": "San Francisco"},    # –ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π country
        {"geo_country": "", "geo_region": "CA", "geo_city": "San Francisco"},       # –ü–æ—Ä–æ–∂–Ω—ñ–π country
        {"geo_country": "X", "geo_region": "CA", "geo_city": "San Francisco"},      # –ö–æ—Ä–æ—Ç–∫–∏–π country
    ]
    
    for geo_data in test_geo_cases:
        original = geo_data.copy()
        cleaned = clean_geo_fields(geo_data)
        print(f"   {original} ‚Üí {cleaned}")
    
    # –¢–µ—Å—Ç 6: –í–∞–ª—ñ–¥–∞—Ü—ñ—è –º–æ–≤
    print("\n6. Language Code Validation:")
    test_languages = [
        "en", "DE", "fr", "xy", "zz",       # –î–≤–æ–±—É–∫–≤–µ–Ω–Ω—ñ –∫–æ–¥–∏ (–í–°–Ü –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—å—Å—è!)
        "zh-tw", "en-us", "fr-ca",          # Locale –∑ –¥–µ—Ñ—ñ—Å–æ–º ‚Üí –ø–µ—Ä—à—ñ 2 –±—É–∫–≤–∏
        "en_US", "zh_CN",                   # Locale –∑ underscore ‚Üí –ø–µ—Ä—à—ñ 2 –±—É–∫–≤–∏
        "english", "german", "japanese",    # –ü–æ–≤–Ω—ñ –Ω–∞–∑–≤–∏ ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è
        "fran√ßais", "espa√±ol", "portugu√™s", # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –Ω–∞–∑–≤–∏ ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è
        "eng", "ger", "jap",                # –°–∫–æ—Ä–æ—á–µ–Ω—ñ ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è
        "123", "toolong", "x", "",          # –ù–µ–≤–∞–ª—ñ–¥–Ω—ñ ‚Üí –ø–æ—Ä–æ–∂–Ω—å–æ
        "unclear", "not detected"           # Access issues ‚Üí –ø–æ—Ä–æ–∂–Ω—å–æ
    ]
    for lang in test_languages:
        result = validate_and_clean_language_code(lang)
        print(f"   '{lang}' ‚Üí '{result}'")
    
    # –¢–µ—Å—Ç 7: –ü–æ–≤–Ω–∏–π clean_gemini_results –∑ –≥–µ–æ–≥–∞—Ñ—ñ—î—é —Ç–∞ –º–æ–≤–∞–º–∏
    print("\n7. Full Gemini Results with Geo and Language Validation:")
    test_gemini_result = {
        "segments_full": "w 3 web",
        "segments_language": "en en",
        "app_platforms": ["windows", "chrome"],
        "primary_language": "english",  # –ü–æ–≤–Ω–∞ –Ω–∞–∑–≤–∞ ‚Üí en
        "geo_country": "USA",  # –ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π!
        "geo_region": "California",
        "geo_city": "San Francisco"
    }
    
    print(f"   Before: {test_gemini_result}")
    cleaned_full = clean_gemini_results(test_gemini_result, "w 3", "test-domain.com")
    print(f"   After:  {cleaned_full}")
    
    # üÜï –¢–µ—Å—Ç 8: –°–ø–µ—Ü—ñ–∞–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ segments_full
    print("\n8. Segments Full Validation Failed Handling:")
    test_cases = [
        {"segments_full": "valid segment"},   # –í–∞–ª—ñ–¥–Ω–∏–π - –∑–∞–ª–∏—à–∞—î—Ç—å—Å—è
        {"segments_full": ""},                # –ü–æ—Ä–æ–∂–Ω—ñ–π - —Å—Ç–∞—î validation_failed
        {"segments_full": "   "},            # –ü—Ä–æ–±—ñ–ª–∏ - —Å—Ç–∞—î validation_failed
        {}                                   # –í—ñ–¥—Å—É—Ç–Ω—î - —Å—Ç–∞—î validation_failed
    ]
    
    for i, case in enumerate(test_cases):
        original = case.copy()
        result = handle_segments_full_validation(case, f"test-domain-{i}.com")
        print(f"   {original} ‚Üí {result}")
    
    # üÜï –¢–µ—Å—Ç 9: –î–µ—Ç–∞–ª—å–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è segments_full
    print("\n9. Detailed Segments Full Validation:")
    validation_test_cases = [
        ("w 3", "w 3", "match"),                    # –¢–æ—á–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        ("w 3", "w3", "normalized_match"),          # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è  
        ("book store", "bookstore", "normalized_match"), # –ù–æ—Ä–º–∞–ª—ñ–∑–æ–≤–∞–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        ("w 3", "w 3 extra", "mismatch"),          # –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Å–µ–≥–º–µ–Ω—Ç–∏
        ("w 3", "web 3", "mismatch"),              # –Ü–Ω—à—ñ —Å–ª–æ–≤–∞
        ("w 3", "", "empty_ai"),                   # –ü–æ—Ä–æ–∂–Ω—ñ–π AI —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        ("", "w 3", "empty_original"),             # –ü–æ—Ä–æ–∂–Ω—ñ–π –æ—Ä–∏–≥—ñ–Ω–∞–ª
    ]
    
    for original, ai_output, expected in validation_test_cases:
        result = validate_segments_full(original, ai_output, f"test-{expected}.com")
        print(f"   '{original}' vs '{ai_output}' ‚Üí {result} ({expected})")
    
    print(f"\n=== Test completed ===")
    print(f"Module loaded successfully with DETAILED validation logging")
    print("üÜï NEW FEATURES:")
    print("   - validate_segments_full() now shows expected vs actual segments")
    print("   - handle_segments_full_validation() sets 'validation_failed' for empty fields")
    print("   - clean_gemini_results() supports domain_full parameter for logging")
    print("   - All validation errors now include specific domain context")